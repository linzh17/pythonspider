{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  解析库使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath常用规则\n",
    "\n",
    "| 表达式 | 描述 |\n",
    "|:------|:-----|\n",
    "| nodename | 选取此节点的所有子节点 |\n",
    "| / | 从当前节点选取直接子节点 |\n",
    "| // | 从当前节点选取子孙节点 |\n",
    "| . | 选取当前节点 |\n",
    "| .. | 选取当前节点的父节点 |\n",
    "| @ | 选取属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 首先导入lxml的etree 模块,可以调用etree.html()对html文本进行初始化,构造XPath解析对象,同时etree模块可以自动修正html文本  \n",
    "> etree.tostring()返回修正后的文本,为bytes类型,需要decode()转成str类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml  import etree\n",
    "text = '''\n",
    "<div>\n",
    "<ul>\n",
    "<li class = \"item-0\"><a href = \"link1.html\">first item</a></li>\n",
    "<li class = \"item-1\"><a href = \"link2.html\">second item</a></li>\n",
    "<li class = \"item-inactive\"><a href = \"link3.html\">third item</a></li>\n",
    "<li class = \"item-1\"><a href = \"link4.html\">fourth item</a></li>\n",
    "<li class = \"item-1\"><a href = \"link5.html\">fifth item</a>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "'''\n",
    "#结果中,li节点被自动补全\n",
    "html = etree.HTML(text)\n",
    "result = etree.tostring(html)\n",
    "print(result.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 直接读取文本进行解析  \n",
    "```html = etree.parse('./test.html',etree.HTMLParser())```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree \n",
    "\n",
    "html = etree.parse('./test.html',etree.HTMLParser())\n",
    "result = etree.tostring(html)\n",
    "print(result.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节点选取 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element html at 0x7fbc6008d408>, <Element body at 0x7fbc60302608>, <Element div at 0x7fbc603187c8>, <Element ul at 0x7fbc6008d448>, <Element li at 0x7fbc6008d488>, <Element a at 0x7fbc6008d508>, <Element li at 0x7fbc6008d548>, <Element a at 0x7fbc6008d588>, <Element li at 0x7fbc6008d5c8>, <Element a at 0x7fbc6008d4c8>, <Element li at 0x7fbc6008d608>, <Element a at 0x7fbc6008d648>, <Element li at 0x7fbc6008d688>, <Element a at 0x7fbc6008d6c8>]\n",
      "[<Element li at 0x7fbc6008d488>, <Element li at 0x7fbc6008d548>, <Element li at 0x7fbc6008d5c8>, <Element li at 0x7fbc6008d608>, <Element li at 0x7fbc6008d688>]\n",
      "<Element li at 0x7fbc6008d488>\n",
      "[<Element a at 0x7fbc603187c8>, <Element a at 0x7fbc60302608>, <Element a at 0x7fbc60302548>, <Element a at 0x7fbc6008d448>, <Element a at 0x7fbc6008d508>]\n",
      "[<Element a at 0x7fbc603187c8>, <Element a at 0x7fbc60302608>, <Element a at 0x7fbc60302548>, <Element a at 0x7fbc6008d448>, <Element a at 0x7fbc6008d508>]\n",
      "['item-1']\n",
      "['item-1']\n",
      "[<Element li at 0x7fbc603187c8>, <Element li at 0x7fbc6008d488>]\n",
      "['\\n    ']\n",
      "['first item', 'fifth item']\n",
      "['first item', 'fifth item', '\\n    ']\n",
      "['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n",
      "[]\n",
      "['first item']\n",
      "['first item']\n",
      "['first item']\n",
      "['fifth item']\n",
      "['first item', 'second item']\n",
      "['third item']\n"
     ]
    }
   ],
   "source": [
    "#example1\n",
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./test.html',etree.HTMLParser())\n",
    "#print(etree.tostring(html))\n",
    "#选取所有节点\n",
    "result = html.xpath('//*')\n",
    "print(result)\n",
    "\n",
    "#选取所有li节点\n",
    "result = html.xpath('//li')\n",
    "print(result)\n",
    "print(result[0])\n",
    "\n",
    "#获取子节点\n",
    "#选择所有li节点的直接子节点a\n",
    "result = html.xpath('//li/a')\n",
    "print(result)\n",
    "\n",
    "#获取子孙节点\n",
    "result = html.xpath('//ul//a')\n",
    "print(result)\n",
    "\n",
    "#获取父节点\n",
    "result = html.xpath('//a[@href=\"link4.html\"]/../@class')\n",
    "print(result)\n",
    "\n",
    "#获取父节点2\n",
    "result = html.xpath('//a[@href=\"link4.html\"]/parent::*/@class')\n",
    "print(result)\n",
    "\n",
    "#属性匹配\n",
    "#用@符号进行属性过滤\n",
    "result = html.xpath('//li[@class=\"item-0\"]')\n",
    "print(result)\n",
    "\n",
    "#文本获取 text()\n",
    "\n",
    "#text()函数前为/,选取直接子节点\n",
    "result = html.xpath('//li[@class=\"item-0\"]/text()')\n",
    "print(result)\n",
    "\n",
    "#\n",
    "result = html.xpath('//li[@class=\"item-0\"]/a/text()')\n",
    "print(result)\n",
    "\n",
    "#获取子孙节点内部的所有文本\n",
    "result = html.xpath('//li[@class=\"item-0\"]//text()')\n",
    "print(result)\n",
    "\n",
    "#属性获取,获取节点的属性\n",
    "result = html.xpath('//li/a/@href')\n",
    "print(result)\n",
    "\n",
    "#属性多值匹配 contains()函数 li节点中有两个值li和li-firsst 所以需要contains()\n",
    "text ='''\n",
    "<li class = \"li li-first\"><a href=\"link.html\">first item</a></li>\n",
    "'''\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[@class=li]/a/text()')\n",
    "print(result)\n",
    "result = html.xpath('//li[contains(@class,\"li\")]/a/text()')\n",
    "print(result)\n",
    "\n",
    "#多属性匹配\n",
    "text = '''\n",
    "<li class=\"li li-first\" name=\"item\"><a href=\"link.html\">first item</a></li>\n",
    "'''\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[contains(@class,\"li\") and @name=\"item\"]/a/text()')\n",
    "print(result)\n",
    "\n",
    "#按序选择\n",
    "html = etree.parse('./test.html',etree.HTMLParser())\n",
    "result = html.xpath('//li[1]/a/text()')\n",
    "print(result)\n",
    "result = html.xpath('//li[last()]/a/text()')\n",
    "print(result)\n",
    "result = html.xpath('//li[position()<3]/a/text()')\n",
    "print(result)\n",
    "result = html.xpath('//li[last()-2]/a/text()')\n",
    "print(result)\n",
    "\n",
    "#节点轴选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiul Soup\n",
    "> 解析工具 自动进行编码转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beautiful soup 初始化\n",
    "> 初始化时会自动更正文档的格式,补全格式  \n",
    "\n",
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"22%\">\n",
    "<col width=\"26%\">\n",
    "<col width=\"26%\">\n",
    "<col width=\"26%\">\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">解析器</th>\n",
    "<th class=\"head\">使用方法</th>\n",
    "<th class=\"head\">优势</th>\n",
    "<th class=\"head\">劣势</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td>Python标准库</td>\n",
    "<td><tt class=\"docutils literal\"><span class=\"pre\">BeautifulSoup(markup,</span>\n",
    "<span class=\"pre\">\"html.parser\")</span></tt></td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>Python的内置标准库</li>\n",
    "<li>执行速度适中</li>\n",
    "<li>文档容错能力强</li>\n",
    "</ul>\n",
    "</td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>Python 2.7.3 or 3.2.2)前\n",
    "的版本中文档容错能力差</li>\n",
    "</ul>\n",
    "</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>lxml HTML 解析器</td>\n",
    "<td><tt class=\"docutils literal\"><span class=\"pre\">BeautifulSoup(markup,</span>\n",
    "<span class=\"pre\">\"lxml\")</span></tt></td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>速度快</li>\n",
    "<li>文档容错能力强</li>\n",
    "</ul>\n",
    "</td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>需要安装C语言库</li>\n",
    "</ul>\n",
    "</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>lxml XML 解析器</td>\n",
    "<td><p class=\"first\"><tt class=\"docutils literal\"><span class=\"pre\">BeautifulSoup(markup,</span>\n",
    "<span class=\"pre\">[\"lxml\",</span> <span class=\"pre\">\"xml\"])</span></tt></p>\n",
    "<p class=\"last\"><tt class=\"docutils literal\"><span class=\"pre\">BeautifulSoup(markup,</span>\n",
    "<span class=\"pre\">\"xml\")</span></tt></p>\n",
    "</td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>速度快</li>\n",
    "<li>唯一支持XML的解析器</li>\n",
    "</ul>\n",
    "</td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>需要安装C语言库</li>\n",
    "</ul>\n",
    "</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>html5lib</td>\n",
    "<td><tt class=\"docutils literal\"><span class=\"pre\">BeautifulSoup(markup,</span>\n",
    "<span class=\"pre\">\"html5lib\")</span></tt></td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>最好的容错性</li>\n",
    "<li>以浏览器的方式解析文档</li>\n",
    "<li>生成HTML5格式的文档</li>\n",
    "</ul>\n",
    "</td>\n",
    "<td><ul class=\"first last simple\">\n",
    "<li>速度慢</li>\n",
    "<li>不依赖外部扩展</li>\n",
    "</ul>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup('<p>Hello</p>','lxml')\n",
    "print(soup.p.srting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本用法\n",
    "> prettify()方法 可以将要解析的字符串以标准的缩进格式输出  \n",
    ">调用soup.title.string,选中html中title节点,调用string属性可以得到文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.prettify())\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择元素 \n",
    "> 元素类型 bs4.element.Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "print(soup.title)\n",
    "print(type(soup.title))\n",
    "print(soup.title.string)\n",
    "print(soup.head)\n",
    "#只会匹配到第一个p节点的内容\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n"
     ]
    }
   ],
   "source": [
    "#获取名称\n",
    "print(soup.title.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['title']}\n",
      "['title']\n",
      "['title']\n"
     ]
    }
   ],
   "source": [
    "#获取属性\n",
    "#attrs返回的是字典形式\n",
    "print(soup.p.attrs)\n",
    "print(soup.p.attrs['class'])\n",
    "#更简单的获取形式\n",
    "#有时候放回结果为字符串,当有多个class属性时,返回列表\n",
    "print(soup.p['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "#获取内容\n",
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "#嵌套获取内容\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "'''\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.head.title)\n",
    "print(type(soup.head.title))\n",
    "print(soup.head.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n",
      "<list_iterator object at 0x7f2ebabda978>\n",
      "0 Once upon a time there were three little sisters; and their names were\n",
      "\n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "2 ,\n",
      "\n",
      "3 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "4  and\n",
      "\n",
      "5 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "6 ;\n",
      "and they lived at the bottom of a well.\n",
      "<generator object descendants at 0x7f2ebabdc780>\n",
      "0 Once upon a time there were three little sisters; and their names were\n",
      "\n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "2 Elsie\n",
      "3 ,\n",
      "\n",
      "4 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "5 Lacie\n",
      "6  and\n",
      "\n",
      "7 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "8 Tillie\n",
      "9 ;\n",
      "and they lived at the bottom of a well.\n"
     ]
    }
   ],
   "source": [
    "#关联选择\n",
    "# 子节点和子孙节点\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "#返回结果为列表形式 ,列表中每个元素为直接子节点,例如返回结果中a节点中的span节点不会被单独\n",
    "#出来\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.p.contents)\n",
    "\n",
    "# 可以用children属性得到相应的结果\n",
    "# children 返回的是生成器类型\n",
    "print(soup.p.children)\n",
    "for i,child in enumerate(soup.p.children):\n",
    "    print(i,child)\n",
    "    \n",
    "#获取子孙节点\n",
    "print(soup.p.descendants)\n",
    "for i,child in enumerate(soup.p.descendants):\n",
    "    print(i,child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n"
     ]
    }
   ],
   "source": [
    "# 获取父节点和祖先节点\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "#获取直接父节点\n",
    "#返回父节点及节点内的内容\n",
    "print(soup.a.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object parents at 0x7f2eba93b9e8>\n",
      "<class 'generator'>\n",
      "[(0, <p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "</p>), (1, <body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "</p>\n",
      "</body>), (2, <html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "</p>\n",
      "</body></html>), (3, <html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "</p>\n",
      "</body></html>)]\n"
     ]
    }
   ],
   "source": [
    "#获取祖先节点\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
    "<span>Elsie</span>\n",
    "</a>\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.a.parents)\n",
    "#返回结果为生成器类型\n",
    "print(type(soup.a.parents))\n",
    "print(list(enumerate(soup.a.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next sibling  hello\n",
      "\n",
      "prev sibling  Once upon a time there were three little sisters; and their names were\n",
      "\n",
      "next siblings [(0, 'hello\\n'), (1, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>), (2, ' and\\n'), (3, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>), (4, ';\\nand they lived at the bottom of a well.')]\n",
      "previous siblings [(0, 'Once upon a time there were three little sisters; and their names were\\n')]\n"
     ]
    }
   ],
   "source": [
    "#获取兄弟节点\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>hello\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "#next_sibling&previous_sibling\n",
    "print('next sibling ',soup.a.next_sibling)\n",
    "print('prev sibling ',soup.a.previous_sibling)\n",
    "\n",
    "#next_siblings&previous_siblings\n",
    "print('next siblings',list(enumerate(soup.a.next_siblings)))\n",
    "print('previous siblings',list(enumerate(soup.a.previous_siblings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "\n",
      "['story']\n"
     ]
    }
   ],
   "source": [
    "# 提取信息\n",
    "#可以通过string ,attrs 获取上述节点的文本或者属性\n",
    "\n",
    "print(soup.a.next_sibling.string)\n",
    "print(list(soup.a.parents)[0].attrs['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  find_all()\n",
    "\n",
    "```find_all( name , attrs , recursive , text , **kwargs )```  \n",
    "find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件.这里有几个例子  \n",
    "\n",
    "##### 过滤器类型 \n",
    "* 字符串  \n",
    "传入一个字符串参数,则会查找与字符串完整相匹配的内容  \n",
    "```\n",
    "soup.find_all('b')\n",
    "# [<b>The Dormouse's story</b>]\n",
    "```  \n",
    "* 正则表达式  \n",
    "bs4通过正则表达式的match()来匹配内容  \n",
    "```\n",
    "import re\n",
    "for tag in soup.find_all(re.compile(\"^b\")):\n",
    "    print(tag.name)\n",
    "# body\n",
    "# b\n",
    "```  \n",
    "* 列表  \n",
    "bs4会将与列表中任一元素匹配的内容返回  \n",
    "```\n",
    "soup.find_all([\"a\", \"b\"])\n",
    "# [<b>The Dormouse's story</b>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "```\n",
    "* True  \n",
    "True 匹配任何值,会查找到所有tag 但是不会返回字符串节点 \n",
    "```\n",
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)\n",
    "# html\n",
    "# head\n",
    "# title\n",
    "# body\n",
    "# p\n",
    "# b\n",
    "# p\n",
    "# a\n",
    "# a\n",
    "# a\n",
    "# p\n",
    "```\n",
    "* 方法  \n",
    "没有合适的过滤器,可以定义一个方法,方法只接受一个元素参数,如果方法返回True 则表示当前元素匹配且被找到,如果不是返回False  \n",
    "```\n",
    "soup.find_all(has_class_but_no_id)\n",
    "# [<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
    "#  <p class=\"story\">Once upon a time there were...</p>,\n",
    "#  <p class=\"story\">...</p>]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find_all()简单的几个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>]\n",
      "[<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
      "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.find_all(\"title\"))\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "print(soup.find_all(\"p\", \"title\"))\n",
    "# [<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
    "\n",
    "print(soup.find_all(\"a\"))\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "print(soup.find_all(id=\"link2\"))\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "import re\n",
    "print(soup.find(text=re.compile(\"sisters\")))\n",
    "# u'Once upon a time there were three little sisters; and their names were\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### name 参数  \n",
    "查找所有名字为name的tag,字符串对象会自动忽略掉  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(\"title\"))\n",
    "# [<title>The Dormouse's story</title>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keyword 参数  \n",
    "如果一个指定的参数不是find_all()的内置参数名,搜索时把该参数当做指定名字tag的属性来搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<div data-foo=\"value\">foo!</div>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(soup.find_all(id='link2'))\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "#如果传入 href 参数,Beautiful Soup会搜索每个tag的”href”属性:\n",
    "soup.find_all(href=re.compile(\"elsie\"))\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "#下面的例子在文档树中查找所有包含 id 属性的tag,无论 id 的值是什么:\n",
    "soup.find_all(id=True)\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "#使用多个指定名字的参数可以同时过滤tag的多个属性:\n",
    "soup.find_all(href=re.compile(\"elsie\"), id='link1')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">three</a>]\n",
    "\n",
    "#有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性:\n",
    "#但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:\n",
    "data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>')\n",
    "data_soup.find_all(attrs={\"data-foo\": \"value\"})\n",
    "# [<div data-foo=\"value\">foo!</div>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 按CSS 搜索  \n",
    "按照CSS类名搜索tag的功能非常实用,但标识CSS类名的关键字 class 在Python中是保留字,使用 class 做参数会导致语法错误.从Beautiful Soup的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(\"a\", class_=\"sister\"))\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_ 参数接受不同类型的过滤器,字符串,正则表达式,方法或True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(class_=re.compile(\"itl\")))\n",
    "\n",
    "def has_six_characters(css_class):\n",
    "    return css_class is not None and len(css_class) == 6\n",
    "print(soup.find_all(class_=has_six_characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag的class 属性是多只属性,按照css类型搜索tag时,可以分别搜索tag中的每个css类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>')\n",
    "css_soup.find_all(\"p\", class_=\"strikeout\")\n",
    "# [<p class=\"body strikeout\"></p>]\n",
    "\n",
    "css_soup.find_all(\"p\", class_=\"body\")\n",
    "# [<p class=\"body strikeout\"></p>]\n",
    "\n",
    "#通过css值完全匹配\n",
    "print(css_soup.find_all(\"p\",class_=\"body strikeout\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### text参数  \n",
    "text参数可以搜索文档中的字符串内容,接受字符串,正则表达式,列表,True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elsie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(soup.find_all(text=\"Elsie\"))\n",
    "\n",
    "soup.find_all(text=[\"Tillie\", \"Elsie\", \"Lacie\"])\n",
    "# [u'Elsie', u'Lacie', u'Tillie']\n",
    "\n",
    "soup.find_all(text=re.compile(\"Dormouse\"))\n",
    "[u\"The Dormouse's story\", u\"The Dormouse's story\"]\n",
    "\n",
    "soup.find_all(\"a\", text=\"Elsie\")\n",
    "# [<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### limit 参数  \n",
    "limit参数限制返回结果的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\", limit=2)\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### recursive参数\n",
    "find_all() 会搜索文档的所有子孙节点,而recursive=False 只搜索直接子节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find()\n",
    "```find( name , attrs , recursive , text , **kwargs )```  \n",
    "只返回文档中符合条件的tag 只得到一个结果,而find_all() 返回所有结果  \n",
    "find_all() 没找到返回空列表,find() 没找到返回None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title')\n",
    "# <title>The Dormouse's story</title>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find_parents() 和 find_parent\n",
    "```\n",
    "find_parents( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "find_parent( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "\n",
    "```  \n",
    "搜索父辈节点 前者返回所有祖先节点 后者返回直接父节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string = soup.find(text=\"Lacie\")\n",
    "a_string\n",
    "# u'Lacie'\n",
    "\n",
    "a_string.find_parents(\"a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "a_string.find_parent(\"p\")\n",
    "# <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "#  <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
    "#  and they lived at the bottom of a well.</p>\n",
    "\n",
    "a_string.find_parents(\"p\", class_=\"title\")\n",
    "# []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find_next_siblings() & find_next_sibling()\n",
    "```\n",
    "find_next_siblings( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "find_next_sibling( name , attrs , recursive , text , **kwargs )\n",
    "```  \n",
    "前者返回后面所有兄弟节点,后者返回后面第一个兄弟节点  \n",
    "##### find_previous_siblings() 和 find_previous_sibling()  \n",
    "```\n",
    "find_previous_siblings( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "find_previous_sibling( name , attrs , recursive , text , **kwargs )\n",
    "```  \n",
    "返回前面所有兄弟节点,返回第一个兄弟节点  \n",
    "#####  find_all_next() 和 find_next()  \n",
    "```\n",
    "find_all_next( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "find_next( name , attrs , recursive , text , **kwargs )\n",
    "```\n",
    "##### find_all_previous() 和 find_previous()   \n",
    "```\n",
    "find_all_previous( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "find_previous( name , attrs , recursive , text , **kwargs )\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSS选择器 \n",
    ".select() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.select(\"title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tag标签逐层查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"body a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\"  id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"html head title\")\n",
    "# [<title>The Dormouse's story</title>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到某个tag标签下的直接子标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"head > title\")\n",
    "# [<title>The Dormouse's story</title>]\n",
    "\n",
    "soup.select(\"p > a\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\"  id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "#nth-of-type 匹配父元素的特定类型的第N个子元素的每个元素\n",
    "soup.select(\"p > a:nth-of-type(2)\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
    "\n",
    "soup.select(\"p > #link1\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select(\"body > a\")\n",
    "# []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到兄弟节点标签 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#link1 ~ .sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\"  id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"#link1 + .sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过CSS的类名查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\".sister\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select(\"[class~=sister]\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tag的id查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#link1\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select(\"a#link2\")\n",
    "# [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过是否存在某个属性来查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"title\"><b>The Dormouse's story</b></p>, <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>, <p class=\"story\">...</p>]\n"
     ]
    }
   ],
   "source": [
    "soup.select('a[href]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "print(soup.select('p[class]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过属性的值查找\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('a[href=\"http://example.com/elsie\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
    "\n",
    "soup.select('a[href^=\"http://example.com/\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select('a[href$=\"tillie\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.select('a[href*=\".com/el\"]')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过语言设置来查找\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p lang=\"en\">Hello</p>,\n",
       " <p lang=\"en-us\">Howdy, y'all</p>,\n",
       " <p lang=\"en-gb\">Pip-pip, old fruit</p>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_markup = \"\"\"\n",
    " <p lang=\"en\">Hello</p>\n",
    " <p lang=\"en-us\">Howdy, y'all</p>\n",
    " <p lang=\"en-gb\">Pip-pip, old fruit</p>\n",
    " <p lang=\"fr\">Bonjour mes amis</p>\n",
    "\"\"\"\n",
    "multilingual_soup = BeautifulSoup(multilingual_markup)\n",
    "multilingual_soup.select('p[lang|=en]')\n",
    "# [<p lang=\"en\">Hello</p>,\n",
    "#  <p lang=\"en-us\">Howdy, y'all</p>,\n",
    "#  <p lang=\"en-gb\">Pip-pip, old fruit</p>]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
